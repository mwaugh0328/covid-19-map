{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# these are new \n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import shutil                   # file management tools \n",
    "import os                       # operating system tools (check files)\n",
    "\n",
    "from census import Census # This is new...\n",
    "\n",
    "import geopandas as gpd # this is the main geopandas \n",
    "from shapely.geometry import Point, Polygon # also needed\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "##########################\n",
    "# Then this stuff below allows us to make a nice inset\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Covid-19 Cases by County Map\n",
    "\n",
    "The code below creates a static map illustrating the prevalence of Covid cases. The interactive map is now housed in the notebook ``us-covid-19-static-map.ipynv``\n",
    "\n",
    "The underlying Covid-19 data is from reporting done by the New York Times and hosted in their data repository on github.\n",
    "\n",
    "### Overview of code\n",
    "\n",
    "Thansk to the [@nytimes](https://github.com/nytimes/covid-19-data). This proved to be very easy given my existing code associated with my project on the [trade war](https://github.com/mwaugh0328/consumption_and_tradewar). The code proceeds in several steps:\n",
    "\n",
    "Thansk to the [@nytimes](https://github.com/nytimes/covid-19-data). This proved to be very easy given my existing code associated with my project on the [trade war](https://github.com/mwaugh0328/consumption_and_tradewar). The code proceeds in several steps:\n",
    "\n",
    "1. Grabs the nytimes data. Their repository provides detailed explanations regarding geography etc. NYC in particular is treated as one region, not by county. \n",
    "\n",
    "2. Merge nytimes data with the geopandas dataframe, add in US Census data (currently just population), then some simple cleaning to prepare for maping.\n",
    "\n",
    "3. Create a static map using geopandas.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- The code below assumes you have the correct shapefiles. If not, or you don't know what I'm talking about run ``download_shapefiles.ipynb`` which pull the correct shapefiles to make the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step \\#1. Grab data from [nytimes repository](https://github.com/nytimes/covid-19-data)\n",
    "\n",
    "Thank you for organizing this. It's very simple..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/nytimes/covid-19-data/raw/master/us-counties.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NYC we will assing it the Mannhatten fips code\n",
    "# Then below to the other new york city counties we \n",
    "# assing them the same case and death data as New York city as a whole\n",
    "\n",
    "nyc = df.county == \"New York City\"\n",
    "df.loc[nyc,\"fips\"] = 36061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date to a datetime object\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = latest_date.strftime(\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = df.loc[latest_date].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important data note** The nytimes dataset reports **cumulative** cases, not the number reported each day. The very first version of this code messed this up. Now it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall[dfall.county == \"New York City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = dfall.cases.sum()\n",
    "\n",
    "print(\"Total US Covid-19 Cases\", total, \"as of\", latest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_deaths = dfall.deaths.sum()\n",
    "\n",
    "print(\"Total US Covid-19 Deaths\", total_deaths, \"as of\", latest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfall[dfall[\"fips\"] == 36061]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get US County and State, Shapefiles\n",
    "\n",
    "The notebook ``download_shapefiles.ipynb`` downloads the requisite shapefiles from the US census. They are unzipped in a folder called shapefiles and then county. So they are assuming some structure behind your folder setup. \n",
    "\n",
    "The following code reads in the shape files and organizes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = \"epsg:2163\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "county_shape = cwd + \"\\\\shapefiles\\\\lake\\\\ne_10m_lakes.shx\"\n",
    "\n",
    "lake_map = gpd.read_file(county_shape)\n",
    "\n",
    "lake_map = lake_map.to_crs({'init': map_projection})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "county_shape = cwd + \"\\\\shapefiles\\\\land\\\\ne_50m_land.shx\"\n",
    "\n",
    "land_map = gpd.read_file(county_shape)\n",
    "\n",
    "land_map = land_map.to_crs({'init': map_projection })\n",
    "\n",
    "land_map = land_map.iloc[0:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "county_shape = cwd + \"\\\\shapefiles\\\\county\\\\tl_2017_us_county.shx\"\n",
    "\n",
    "us_map = gpd.read_file(county_shape)\n",
    "\n",
    "us_map = us_map.to_crs({'init': map_projection })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"geometry\"] = us_map[\"geometry\"].simplify(200)\n",
    "# This was important. The geometry in the tigerline file si\n",
    "# too fine, orginal map was 350mb. simply basicly simplifies the geometry,\n",
    "# making the map take up less memory and load faster. Still not sure\n",
    "# what the number exactly means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"area_fips\"] = (us_map.STATEFP.astype(str) + us_map.COUNTYFP.astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Step \\#3 Merge and Clean\n",
    "\n",
    "The next couple of cells download the requisite shapefiles from the US census. They are unzipped in a folder called shapefiles and then county. So they are assuming some structure behind your folder setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map = us_map.merge(dfall, left_on='area_fips',\n",
    "                      right_on = \"fips\", how = \"left\", indicator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below fills in the NYC region with the NYC values. So in the hover map, when you hover over say Brookly, it will show the value for the NYC region. I then added a data note column that will inform the reader of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in Queens (36081), Bronx (36005, Richmond(36085), Brooklyn (36047)\n",
    "nyc_counties = [36081,36005,36085,36047]\n",
    "\n",
    "us_map.loc[us_map.area_fips.isin(nyc_counties), \"deaths\"] = us_map.loc[us_map.area_fips == 36061,\"deaths\"].values[0]\n",
    "\n",
    "us_map.loc[us_map.area_fips.isin(nyc_counties), \"cases\"] = us_map.loc[us_map.area_fips == 36061,\"cases\"].values[0]\n",
    "\n",
    "us_map[\"Notes\"] = \"\"\n",
    "\n",
    "all_nyc_counties = [36081,36005,36085,36047,36061]\n",
    "\n",
    "us_map.loc[us_map.area_fips.isin(all_nyc_counties), \"Notes\"] = \"NYC counties are treated as one region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nyc_counties = [36081,36005,36085,36047,36061]\n",
    "\n",
    "us_map.loc[us_map.area_fips.isin(all_nyc_counties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us_map[[\"NAME\",\"NAMELSAD\",\"county\",\"state\", \"cases\"]].head(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm from Alaska, so this next step is always painfull. Drop states and territories who are not part of the \"lower 48\", contiguous US. Still not clear how fix this in geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map.set_index(\"STATEFP\", inplace = True)\n",
    "\n",
    "drop_list = [\"02\",\"15\",\"72\",\"78\",\"69\",\"66\",\"60\",]\n",
    "\n",
    "us_map.drop(drop_list, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = cwd + \"\\\\shapefiles\\\\state\\\\tl_2017_us_state.shx\"\n",
    "\n",
    "state_map = gpd.read_file(state_shape)\n",
    "\n",
    "state_map = state_map.to_crs({'init': map_projection })\n",
    "\n",
    "state_map[\"geometry\"] = state_map[\"geometry\"].simplify(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_fp_dict = dict(zip(state_map.STATEFP, state_map.STUSPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map.set_index(\"STATEFP\", inplace = True)\n",
    "\n",
    "drop_list = [\"02\",\"15\",\"72\",\"78\",\"69\",\"66\",\"60\",]\n",
    "\n",
    "state_map.drop(drop_list, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"STSPS\"] = us_map[\"STATEFP\"].map(state_fp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"NAME\"] = us_map[\"NAME\"] + \", \" + us_map[\"STSPS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map.set_index(\"STATEFP\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us_map[\"cases\"].replace(\"nan\", np.nan, inplace = True)\n",
    "\n",
    "#us_map[\"cases\"] = us_map[\"cases\"].str.replace(',','')\n",
    "\n",
    "#us_map[\"cases\"] = us_map[\"cases\"].astype(int)\n",
    "\n",
    "us_map[\"cases_label\"] = us_map[\"cases\"].round(0)\n",
    "\n",
    "us_map[\"cases_label\"] = us_map[\"cases_label\"].map('{:,.0f}'.format)\n",
    "\n",
    "us_map[\"deaths_label\"] = us_map[\"deaths\"].round(0)\n",
    "\n",
    "us_map[\"deaths_label\"] = us_map[\"deaths_label\"].map('{:,.0f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Census Data\n",
    "\n",
    "Here I add this in. MY api key is posted here, please be respectfull of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = '34e40301bda77077e24c859c6c6c0b721ad73fc7'\n",
    "# This is my api_key, # don't abuse this.\n",
    "\n",
    "c = Census(my_api_key)\n",
    "# This will create an object c which has methods associated with it.\n",
    "# We will see  these below.\n",
    "\n",
    "code = (\"NAME\",\"B01001_001E\") \n",
    "# Get more stuff from the cencuss if we want...\n",
    "\n",
    "county_2017 = pd.DataFrame(c.acs5.get(code, \n",
    "                                         {'for': 'county:*'}, year=2017))\n",
    "                                         # Same deal, but we specify county then the wild card\n",
    "                                         # On the example page, there are ways do do this, only by state\n",
    "        \n",
    "county_2017 = county_2017.rename(columns = {\"B01001_001E\":\"2017_population\"})\n",
    "\n",
    "county_2017[\"GEOFIPS\"] = (county_2017[\"state\"] + county_2017[\"county\"]).astype(int)\n",
    "\n",
    "county_2017[\"2017_population\"] = county_2017[\"2017_population\"].astype(float)\n",
    "\n",
    "county_2017.set_index([\"GEOFIPS\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Merge the Census and final preperations for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map = us_map.merge(county_2017[[\"2017_population\"]], \n",
    "                      left_on='area_fips', right_on = \"GEOFIPS\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"pop_label\"] = us_map[\"2017_population\"].map('{:,.0f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_cases = [0,1,5,10,100,250,500,1000,5000,10000,np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"q_cases\"]= pd.cut(us_map[\"cases\"],q_cases, labels=range(0,10))\n",
    "us_map[\"q_deaths\"]= pd.cut(us_map[\"deaths\"],q_cases, labels=range(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"q_deaths\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_map[\"cases_label\"].replace(\"nan\", \"None reported\", inplace = True)\n",
    "us_map[\"deaths_label\"].replace(\"nan\", \"None reported\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final issue is to create the borders associated with the great lakes. The issue is that the tigerline shape files just extend boundries into the waterline. And the associated coastline maps are (i) not polygons and (ii) looked messed up. So per above, I found another shape file of lakes. Then I will use geopandas built in set operations to essentially \"punch out\" the holes associated with the great lakes. \n",
    "\n",
    "[https://geopandas.org/set_operations.html](https://geopandas.org/set_operations.html)\n",
    "\n",
    "**Note** for teaching purposes, it's worth messing around with the ``how`` operations to understand what is going on here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This operation will take care of the coastline\n",
    "\n",
    "us_map = gpd.overlay(us_map, land_map,  how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_lakes = [\"Lake Superior\", \"Lake Michigan\", \"Lake Erie\",\"Lake Superior\"\"Lake Huron\"]\n",
    "\n",
    "us_map = gpd.overlay(us_map, lake_map[lake_map.name.isin(great_lakes)],  how='difference')\n",
    "# this is the key operation...note that the order matters on the difference operation. output is same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = gpd.overlay(state_map, land_map,  how='intersection')\n",
    "\n",
    "state_map = gpd.overlay(state_map, lake_map[lake_map.name.isin(great_lakes)],  how='difference')\n",
    "# Do the same thing for the state map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step \\# 4. Create a Static map\n",
    "\n",
    "Below is a set of code and lots of tricks to make a nice looking static map using Geopandas build in functionality. The output file is a ``.png`` file. Should enhance this by adding the date and generating the maps by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize = (12,8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.rcParams.update(plt.rcParamsDefault) # This will reset defaluts...\n",
    "\n",
    "#################################################################################\n",
    "# This is for the colorbar...\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "\n",
    "#################################################################################\n",
    "## This creates a discrete colorbar scheme...\n",
    "# https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "\n",
    "N = 10\n",
    "\n",
    "base = plt.cm.get_cmap(\"RdBu_r\")\n",
    "\n",
    "color_list = base(np.linspace(0, 1, N))\n",
    "\n",
    "cmap_name = base.name + str(N)\n",
    "\n",
    "dcmap =  base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "#################################################################################\n",
    "# This is the normal mapping...\n",
    "\n",
    "#us_map[us_map.q_cases.isna()].plot(alpha = 0.25, color = \"grey\", ax = ax,)\n",
    "\n",
    "us_map.plot(column='q_cases', ax = ax,\n",
    "              # THIS IS NEW, it says color it based on this column\n",
    "             cmap=dcmap, \n",
    "             alpha = 0.75,\n",
    "             vmin=0, vmax=us_map.q_cases.max())\n",
    "\n",
    "#################################################################################\n",
    "# This then alows me to generate and edit the colorbar....\n",
    "# https://stackoverflow.com/questions/53158096/editing-colorbar-legend-in-geopandas\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=dcmap)\n",
    "sm._A = []\n",
    "cbr = fig.colorbar(sm, cax=cax)\n",
    "\n",
    "cbr.set_label('Number of Covid Cases')\n",
    "cbr.set_alpha(0.15)\n",
    "\n",
    "cbr.set_ticks([0, 0.10, 0.20, 0.30,0.40,0.50,0.60,0.70,0.80, 0.90])\n",
    "cbr.set_ticklabels(q_cases, update_ticks=True)\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "state_map.geometry.boundary.plot(color=None, edgecolor='k', alpha = 0.35, ax = ax)\n",
    "\n",
    "#coast_map.plot(color='k', edgecolor='k', alpha = 0.25, ax = ax)\n",
    "\n",
    "#################################################################################\n",
    "# Then some final stuff to clean things up....\n",
    "\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "ax.get_xaxis().set_visible(False)\n",
    "\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "title = \"Covid-19 Cases by County as of \" + latest_date + \", Total Cases: \" + f\"{total:,d}\"\n",
    "title_death = \"Covid-19 Deaths by County as of \" + latest_date + \", Total Deaths: \" + f\"{total_deaths:,d}\"\n",
    "ax.set_title(title, fontsize = 16, loc= \"left\" )\n",
    "\n",
    "plt.savefig(\"covid-19-map.png\", bbox_inches = \"tight\", dip = 1200)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
